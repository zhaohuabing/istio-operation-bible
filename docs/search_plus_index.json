{"./":{"url":"./","title":"Introduction","keywords":"","body":"Istio 运维实战 前言 通过将微服务中原本在 SDK 中实现的应用流量管理、可见性、通信安全等服务治理能力下放到一个专门的“服务网格”基础设施中，Istio 解开了微服务的服务治理需求和业务逻辑之间的代码、编译、部署时机等的耦合，让微服务真正做到了承诺的“按需选择开发语言”，“独立部署升级”等能力，提升了微服务开发和部署的敏捷性，释放了微服务模式的生产力。 然而，“服务网格”这一基础设施的引入也给整个微服务的运维技术栈带来了新的挑战。对于运维同学来说，Istio 和 Envoy 的运维存在着较陡的学习曲线。TCM（Tencent Cloud Mesh）团队是业内最早一批接触服务网格技术的人员之一，有着大量 Istio/Envoy 故障排查和运维经验。本电子书记录了 TCM 团队从大量实际案例中总结出来的 Istio 运维经验，以及使用 Istio 的最佳实践，希望对大家有所帮助。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/debug-istio/":{"url":"content/debug-istio/","title":"Istio 调试指南","keywords":"","body":"服务网格为微服务提供了一个服务通信的基础设施层，统一为上层的微服务提供了服务发现，负载均衡，重试，断路等基础通信功能，以及服务路由，灰度发布，chaos测试等高级管控功能。 服务网格的引入大大降低了个微服务应用的开发难度，让微服务应用开发人员不再需要花费大量时间用于保障底层通讯的正确性上，而是重点关注于产生用户价值的业务需求。 然而由于微服务架构的分布式架构带来的复杂度并未从系统中消失，而是从各个微服务应用中转移到了服务网格中。由服务网格对所有微服务应用的通讯进行统一控制，好处是可以保证整个系统中分布式通讯策略的一致性，并可以方便地进行集中管控。 除微服务之间分布式调用的复杂度之外，服务网格在底层通讯和微服务应用之间引入了新的抽象层，为系统引入了一些额外的复杂度。在此情况下，如果服务网格自身出现故障，将对上层的微服务应用带来灾难性的影响。 当系统中各微服务应用之间的通讯出现异常时，我们可以通过服务网格提供的分布式调用跟踪，故障注入，服务路由等手段快速进行分析和处理。但如果服务网格系统自身出现问题的话，我们如何才能快速进行分析处理呢？ Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/debug-istio/debug-with-envoy-log.html":{"url":"content/debug-istio/debug-with-envoy-log.html","title":"数据面 Envoy 日志调试指南","keywords":"","body":"数据面 Envoy 日志调试指南 1. 问题背景 这是使用 istio 最常见的困境：在微服务中引入 envoy 作为代理后，当流量访问和预期行为不符时，用户很难快速确定问题是出在哪个环节。客户端收到的异常响应，诸如 403、404、503 或者连接中断等，可能是链路中任一 sidecar 执行流量管控的结果， 但也有可能是来自某个服务的合理逻辑响应。 特别的，当 service mesh 系统的维护者和应用程序的开发者来自不同的团队时，问题尤为凸显。 在 mesh 中引入全链路跟踪系统，可以解决部分问题，我们可以知道请求到达了哪些工作负载，但是对于中断的异常请求，我们仍然很难确定原因。 因为本着最大透明化（Maximize Transparency）的设计目标，istio 的遥测系统会尽量屏蔽掉 sidecar 的存在。另一方面，用户自行维护一套全链路跟踪系统成本也很高，受限于遥测采样率和有限的协议支持，我们通常无法采集所有链路数据。 幸运的是，envoy 本身可以记录流量的信息，本文主要介绍如何利用 envoy 日志，对类似问题进行定位。 2. Envoy 流量模型 我们先看看 envoy 的流量模型： 监听，接受连接 根据用户流量操纵规则，进行流量特征识别 进行流量操纵，如负载均衡，转发，拒绝等 在以上流程中， Envoy 接受请求流量叫做 Downstream，Envoy 发出请求流量叫做Upstream。在处理Downstream 和 Upstream 过程中， 分别会涉及2个流量端点，即请求的发起端和接收端： 图片 - envoy-model 在这个过程中， envoy 会根据用户规则，计算出符合条件的转发目的主机集合，这个集合叫做 UPSTREAM_CLUSTER, 并根据负载均衡规则，从这个集合中选择一个 host 作为流量转发的接收端点，这个 host 就是 UPSTREAM_HOST。 以上就是 envoy 请求处理的 流量五元组信息， 这是 envoy 日志里最重要的部分，通过这个五元组我们可以准确的观测流量「从哪里来」和「到哪里去」。 UPSTREAM_CLUSTER DOWNSTREAM_REMOTE_ADDRESS DOWNSTREAM_LOCAL_ADDRESS UPSTREAM_LOCAL_ADDRESS UPSTREAM_HOST 3. Helloworld example 在 Istio 场景中，envoy 既可以是正向代理，也可以是反向代理。在上图中， 如果envoy 处理的是 outbound 流量， 业务容器是作为 Downstream 端点（右边）；如果 envoy 处理的是 inbound 流量， 业务容器是作为 Upstream 端点（左边）。 Istio 中默认不开启 envoy 中的访问日志，需要手动打开，将 istio 配置中 accessLogFile 设置为 /dev/stdout： % kubectl -n istio-system edit cm istio ...... # Set accessLogFile to empty string to disable access log. accessLogFile: \"/dev/stdout\" # 开启日志 accessLogEncoding: 'JSON' # 默认日志是单行格式， 可选设置为 JSON ...... 我们以 sleep pod 访问 hello 服务来举例说明： kubectl apply -f sleep-hello.yaml 图片 - image-20200212222251433 该文件定义了 2个版本的 helloworld 和一个 sleep Pod，helloworld service 的端口是 4000， 而 pod 的端口是5000。 从 sleep Pod 中去访问 helloworld 服务, 确认应用正常： % SLEEP_POD=$(kubectl get pod -l app=sleep -o jsonpath=\"{.items[0].metadata.name}\") % HELLO_V1_POD=$(kubectl get pod -l app=helloworld -l version=v1 -o jsonpath=\"{.items[0].metadata.name}\") % kubectl exec -it $SLEEP_POD -csleep -- sh / # curl helloworld:4000/hello 这时候我们可以去分析 2 个 pod 各自的envoy 日志： 图片 - image-20200212222055391 用一张图来说明： 图片 - downstream-upstream 从日志中我们可以分析出： 对于 sleep pod， sleep app 发出的流量目的端是 hello service ip 和 service port，sleep envoy 处理的是 outbound 流量， envoy 根据规则选择的 「UPSTREAM_CLUSTER 」是outbound|4000||helloworld.default.svc.cluster.local, 然后转发给其中的一个 「UPSTREAM_HOST 」, 也就是 hello pod 的 ip 和port。 对于 hello pod，其 envoy 处理的是 inbound 流量，envoy 根据规则选择的 「UPSTREAM_CLUSTER 」 是inbound|4000|http|helloworld.default.svc.cluster.local, 其中的 「UPSTREAM_HOST 」 是 「127.0.0.1:5000 」, 也就是该 pod 里的 hello app。 因此，我们可以总结出 istio 中流量端点值的逻辑规则： UPSTREAM_HOST 上游主机的 host，表示从 envoy 发出的请求的目的端，通常是「ip:port」 通常来说，对于 outbound cluster，此值是「上游pod-ip : pod-port」 ，而对于 inbound cluster，此值是「127.0.0.1 : pod-port」 UPSTREAM_LOCAL_ADDRESS 上游连接中，当前 envoy 的本地地址，此值是「当前pod-ip : 随机端口」 DOWNSTREAM_LOCAL_ADDRESS 下游连接中，当前 envoy 的本地地址。 通常来说，对于 outbound cluster，此值是「目的service-ip : service-port 」，而对于 inbound cluster，此值是「当前pod-ip : pod-port」 DOWNSTREAM_REMOTE_ADDRESS 下游连接中远端地址。 通常来说，对于 outbound cluster，此值是「当前pod-ip : 随机端口 」，而对于 inbound cluster，此值是「下游pod-ip : 随机端口」 4. Envoy 日志格式 envoy 允许定制日志格式， 格式通过若干「Command Operators」组合，用于提取请求信息，istio 没有使用 envoy 默认的日志格式， istio 定制的访问日志格式如下： 图片 - image-20200205002607125 完整的「Command Operators」含义可查阅 Envoy Access logging Command Operators 除了以上流量五元组，流量分析中常用的重要信息还有： RESPONSE_CODE 响应状态码 RESPONSE_FLAGS 很重要的信息，envoy 中自定义的响应标志位， 可以认为是envoy 附加的流量状态码。 如 「NR」表示找不到路由，「UH」表示upstream cluster 中没有健康的 host，「RL」表示触发 rate limit，「UO」触发断路器。 RESPONSE_FLAGS 可选值有十几个，这些信息在调试中非常关键。 X-REQUEST-ID 一次 C 到 S 的 http 请求，envoy 会在 C 端生产 request id，并附加到 header 中，传递到 S 端，在 2 端的日志中都会记录该值， 因此可以通过这个 ID 关联请求的上下游。注意不要和全链路跟踪中的 trace id 混淆。 ROUTE_NAME 匹配执行的路由名称 5. 场景：判断异常返回是来自业务还是 sidecar？ 比如我们希望所有请求 helloworld 都路由到 v1 版本，创建对应的 virtual service： % kubectl apply -f hello-v1-virtualservice.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: hello spec: hosts: - \"helloworld\" http: - route: - destination: host: helloworld subset: v1 port: number: 4000 从 sleep 中访问发现响应 503： 图片 - image-20200212222518280 如果没有上下文，我们很难判断 503 是来自业务容器还是 sidecar，查看 sleep 和 hello 的 envoy 日志，可以发现：hello pod 的envoy 没有接受到请求，sleep pod 的 envoy 里日志： 图片 - image-20200212222631659 其中\"response_flags\": \"NR\" 表示「No route configured」，也就是 envoy 找不到路由，我们可以判断出该异常是有 envoy 返回。 通过简单的分析就可以找到原因， 我们在VirtualService 中使用的 Destination 没有定义，将其补上： % kubectl apply -f hello-v1-destinationrule.yaml apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: hello spec: host: helloworld subsets: - name: v1 labels: version: v1 再次访问请求正常，日志中response_flags 为空： 图片 - image-20200212222913583 6. 开启 debug 模式 Envoy 默认日志级别是 info，其日志内容能满足大部分调试场景需求，但对于比较复杂的异常，我们往往还需要开启 debug 级别，能获取到更多的流量处理过程和信息，对某个特定的 pod，调整日志级别为 debug 的命令： kubectl exec {POD-NAME} -c istio-proxy -- curl -X POST http://127.0.0.1:15000/logging?level=debug Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/common-problem/":{"url":"content/common-problem/","title":"Istio 常见问题","keywords":"","body":"介绍在使用 Istio 过程中可能遇到的一些常见问题的解决方法. Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/common-problem/application-start-fail.html":{"url":"content/common-problem/application-start-fail.html","title":"应用程序启动失败/启动时无法访问网络","keywords":"","body":"应用程序启动失败/启动时无法访问网络 故障现象 该问题的表现是安装了 sidecar proxy 的应用在启动后的一小段时间内无法通过网络访问 pod 外面的服务。应用在启动时通常会从一些外部服务中获取数据，并采用这些数据对自身进行初始化。例如从配置中心读取程序配置，从数据库中初始化程序用户信息等。而安装了 sidecar proxy 的应用在启动后的一小段时间内网络是不通的。如果应用代码中没有合适的容错和重试逻辑，该问题常常会导致应用启动失败。 故障原因 如下图所示，Envoy 启动后会通过 xDS 协议向 pilot 请求服务和路由配置信息，Pilot 收到请求后会根据 Envoy 所在的节点（pod或者VM）组装配置信息，包括 Listener、Route、Cluster等，然后再通过 xDS 协议下发给 Envoy。根据 Mesh 的规模和网络情况，该配置下发过程需要数秒到数十秒的时间。在这段时间内，由于初始化容器已经在 pod 中创建了 Iptables rule 规则，因此应用向外发送的网络流量会被重定向到 Envoy ，而此时 Envoy 中尚没有对这些网络请求进行处理的监听器和路由规则，无法对此进行处理，导致网络请求失败。（关于 Envoy sidecar 初始化过程和 Istio 流量管理原理的更多内容，可以参考这篇文章 Istio流量管理实现机制深度解析）。 解决方案 参见：最佳实践-在 Sidecar 初始化完成后再启动应用容器 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/common-problem/external-name-service-highjacks.html":{"url":"content/common-problem/external-name-service-highjacks.html","title":"ExternalName Service 劫持了其他服务流量","keywords":"","body":"ExternalName Service 劫持了其他服务流量 故障现象 如果网格内存在一个 ExternalName 类型 Service, 网格内访问其他外部服务的的某一端口，如果这个端口刚好和该 ExternalName Service 重叠，那么流量会被路由到这个 ExternalName Service 对应的 CDS。 故障重现 正常情况 在 namespace sample 安装 sleep pod： kubectl create ns sample kubectl label ns sample istio-injection=enabled kubectl -nsample apply -f https://raw.githubusercontent.com/istio/istio/1.11.4/samples/sleep/sleep.yaml 通过 sleep 访问外部服务 https://httpbin.org:443, 请求成功： kubectl -nsample exec sleep-74b7c4c84c-22zkq -- curl -I https://httpbin.org HTTP/2 200 ...... 从 access log 确认流量是从PassthroughCluster 出去，符合预期： \"- - -\" 0 - - - \"-\" 938 5606 1169 - \"-\" \"-\" \"-\" \"-\" \"18.232.227.86:443\" PassthroughCluster 172.24.0.10:42434 18.232.227.86:443 172.24.0.10:42432 - - 异常情况 现在 在 default 下创建一个 ExternalName 类型的 Service, 端口也是 443: kind: Service apiVersion: v1 metadata: name: my-externalname spec: type: ExternalName externalName: bing.com ports: - port: 443 targetPort: 443 通过 sleep 访问外部服务 https://httpbin.org:443, 请求失败： kubectl -nsample exec sleep-74b7c4c84c-22zkq -- curl -I https://httpbin.org curl: (60) SSL: no alternative certificate subject name matches target host name 'httpbin.org' More details here: https://curl.se/docs/sslcerts.html ...... 查看 access log, 发现请求外部服务，被错误路由到了 my-externalname 的 ExternalName Service: \"- - -\" 0 - - - \"-\" 706 5398 67 - \"-\" \"-\" \"-\" \"-\" \"204.79.197.200:443\" outbound|443||my-externalname.default.svc.cluster.local 172.24.0.10:56806 34.192.79.103:443 172.24.0.10:36214 httpbin.org - 故障原因 通过对比 sleep pod 前后两次的 xDS， 发现增加了 ExternalName Service 后，xDS 里会多一个 LDS 0.0.0.0_443, 该 LDS 包括一个default_filter_chain 会把该 LDS 中其他filter chain 没有match 到的流量，都路由到这个default_filter_chain 中的cluster，也就是 my-externalname 对应的 CDS: 解决方案 该问题属于 istio 实现缺陷，相关 issue： https://github.com/istio/istio/issues/20703 目前的解决方案是避免 ExternalName Service 和其他服务端口冲突。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/best-practice/":{"url":"content/best-practice/","title":"Istio 最佳实践","keywords":"","body":"介绍用户从 Spring Cloud，Dubbo 等传统微服务框架迁移到 Istio 服务网格时的最佳实践。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/best-practice/startup-dependence.html":{"url":"content/best-practice/startup-dependence.html","title":"Sidecar 初始化完成后再启动应用程序","keywords":"","body":"Sidecar 初始化完成后再启动应用程序 为什么需要配置 Sidecar 和应用程序的启动顺序？ 在安装了 Sidecar Proxy 的 Pod 中，应用发出的外部网络请求会被 Iptables 规则重定向到 Proxy 中。如果应用发出请求时 Proxy 还未初始化完成，则 Proxy 无法对请求进行正确路由，导致请求失败。该问题导致的故障现象参见 常见问题-应用程序启动失败/启动时无法访问网络。 配置方法 - Istio 1.7 及之后版本 Istio 1.7 及之后的版本中，可以通过下面的方法配置在 Sidecar 初始化完成后再启动应用容器。 全局配置： 在 istio-system/istio ConfigMap 中将 holdApplicationUntilProxyStarts 这个全局配置项设置为 true。 apiVersion: v1 data: mesh: |- defaultConfig: holdApplicationUntilProxyStarts: true 按 Deployment 配置： 如果不希望该配置全局生效，则可以通过下面的 annotation 在 Deployment 级别进行配置。 template: metadata: annotations: proxy.istio.io/config: '{ \"holdApplicationUntilProxyStarts\": true }' 实现原理：在开启 holdApplicationUntilProxyStarts 选项后，Istio Sidecar Injector Webhook 会在 Pod 中插入下面的 yaml 片段。该 yaml 片段在 sidecar proxy 的 postStart 生命周期时间中执行了 pilot-agent wait 命令。该命令会检测 proxy 的状态，待 proxy 初始化完成后再启动 pod 中的下一个容器。这样，在应用容器启动时，sidecar proxy 已经完成了配置初始化，可以正确代理应用容器的对外网络请求。 spec: containers: - name: istio-proxy lifecycle: postStart: exec: command: - pilot-agent - wait 配置方法 - Istio 1.7 之前的版本 Istio 1.7 之前的版本没有直接提供配置 Sidecar 和应用容器启动顺序的能力。由于 Istio 新版本中解决了老版本中的很多故障，建议尽量升级到新版本。如果由于特殊原因还要继续使用 Istio 1.7 之前的版本，可以在应用进程启动时判断 Envoy sidecar 的初始化状态，待其初始化完成后再启动应用进程。 Envoy 的健康检查接口 localhost:15020/healthz/ready 会在 xDS 配置初始化完成后才返回 200，否则将返回 503，因此可以根据该接口判断 Envoy 的配置初始化状态，待其完成后再启动应用容器。我们可以在应用容器的启动命令中加入调用 Envoy 健康检查的脚本，如下面的配置片段所示。在其他应用中使用时，将 start-awesome-app-cmd 改为容器中的应用启动命令即可。 apiVersion: apps/v1 kind: Deployment metadata: name: awesome-app-deployment spec: selector: matchLabels: app: awesome-app replicas: 1 template: metadata: labels: app: awesome-app spec: containers: - name: awesome-app image: awesome-app ports: - containerPort: 80 command: [\"/bin/bash\", \"-c\"] args: [\"while [[ \\\"$(curl -s -o /dev/null -w ''%{http_code}'' localhost:15020/healthz/ready)\\\" != '200' ]]; do echo Waiting for Sidecar;sleep 1; done; echo Sidecar available; start-awesome-app-cmd\"] 解耦应用服务之间的启动依赖关系 以上配置的思路是控制 pod 中容器的启动顺序，在 Envoy sidecar 初始化完成后再启动应用容器，以确保应用容器启动时能够通过网络正常访问其他服务。但即使 pod 中对外的网络访问没有问题，应用容器依赖的其他服务也可能由于尚未启动，或者某些问题而不能在此时正常提供服务。要彻底解决该问题，建议解耦应用服务之间的启动依赖关系，使应用容器的启动不再强依赖其他服务。 在一个微服务系统中，原单体应用中的各个业务模块被拆分为多个独立进程（服务）。这些服务的启动顺序是随机的，并且服务之间通过不可靠的网络进行通信。微服务多进程部署、跨进程网络通信的特定决定了服务之间的调用出现异常是一个常见的情况。为了应对微服务的该特点，微服务的一个基本的设计原则是 “design for failure”，即需要以优雅的方式应对可能出现的各种异常情况。当在微服务进程中不能访问一个依赖的外部服务时，需要通过重试、降级、超时、断路等策略对异常进行容错处理，以尽可能保证系统的正常运行。 Envoy sidecar 初始化期间网络暂时不能访问的情况只是放大了微服务系统未能正确处理服务依赖的问题，即使解决了 Envoy sidecar 的依赖顺序，该问题依然存在。假设应用启动时依赖配置中心，配置中心是一个独立的微服务，当一个依赖配置中心的微服务启动时，配置中心有可能尚未启动，或者尚未初始化完成。在这种情况下，如果在代码中没有对该异常情况进行处理，也会导致依赖配置中心的微服务启动失败。在一个更为复杂的系统中，多个微服务进程之间可能存在网状依赖关系，如果没有按照 “design for failure” 的原则对微服务进行容错处理，那么只是将整个系统启动起来就将是一个巨大的挑战。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/best-practice/method-level-tracing.html":{"url":"content/best-practice/method-level-tracing.html","title":"在 Istio 中实现方法级调用跟踪","keywords":"","body":"本文将通过一个网上商店的示例程序介绍如何利用 Spring 和 OpenTracing 简化应用程序的 Tracing 上下文传递，以及如何在 Istio 提供的进程间调用跟踪基础上实现方法级别的细粒度调用跟踪。 分布式调用跟踪和OpenTracing规范 什么是分布式调用跟踪？ 相比传统的“巨石”应用，微服务的一个主要变化是将应用中的不同模块拆分为了独立的进程。在微服务架构下，原来进程内的方法调用成为了跨进程的RPC调用。相对于单一进程的方法调用，跨进程调用的调试和故障分析是非常困难的，很难用传统的调试器或者日志打印来对分布式调用进行查看和分析。 如上图所示，一个来自客户端的请求经过了多个微服务进程。如果要对该请求进行分析，则必须将该请求经过的所有服务的相关信息都收集起来并关联在一起，这就是“分布式调用跟踪”。 什么是OpenTracing？ CNCF OpenTracing项目 OpenTracing是CNCF（云原生计算基金会）下的一个项目，其中包含了一套分布式调用跟踪的标准规范，各种语言的API，编程框架和函数库。OpenTracing的目的是定义一套分布式调用跟踪的标准，以统一各种分布式调用跟踪的实现。目前已有大量支持OpenTracing规范的Tracer实现，包括Jager,Skywalking,LightStep等。在微服务应用中采用OpenTracing API实现分布式调用跟踪，可以避免vendor locking，以最小的代价和任意一个兼容OpenTracing的基础设施进行对接。 OpenTracing概念模型 OpenTracing的概念模型参见下图： 图源自 https://opentracing.io/ 如图所示，OpenTracing中主要包含下述几个概念： Trace： 描述一个分布式系统中的端到端事务，例如来自客户端的一个请求。 Span：一个具有名称和时间长度的操作，例如一个REST调用或者数据库操作等。Span是分布式调用跟踪的最小跟踪单位，一个Trace由多段Span组成。 Span context：分布式调用跟踪的上下文信息，包括Trace id，Span id以及其它需要传递到下游服务的内容。一个OpenTracing的实现需要将Span context通过某种序列化机制(Wire Protocol)在进程边界上进行传递，以将不同进程中的Span关联到同一个Trace上。这些Wire Protocol可以是基于文本的，例如HTTP header，也可以是二进制协议。 OpenTracing数据模型 一个Trace可以看成由多个相互关联的Span组成的有向无环图（DAG图）。下图是一个由8个Span组成的Trace： [Span A] ←←←(the root span) | +------+------+ | | [Span B] [Span C] ←←←(Span C is a `ChildOf` Span A) | | [Span D] +---+-------+ | | [Span E] [Span F] >>> [Span G] >>> [Span H] ↑ ↑ ↑ (Span G `FollowsFrom` Span F) 上图的trace也可以按照时间先后顺序表示如下： ––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–> time [Span A···················································] [Span B··············································] [Span D··········································] [Span C········································] [Span E·······] [Span F··] [Span G··] [Span H··] Span的数据结构中包含以下内容： name: Span所代表的操作名称，例如REST接口对应的资源名称。 Start timestamp: Span所代表操作的开始时间 Finish timestamp: Span所代表的操作的的结束时间 Tags：一系列标签，每个标签由一个key value键值对组成。该标签可以是任何有利于调用分析的信息，例如方法名，URL等。 SpanContext：用于跨进程边界传递Span相关信息，在进行传递时需要结合一种序列化协议（Wire Protocol）使用。 References：该Span引用的其它关联Span，主要有两种引用关系，Childof和FollowsFrom。 Childof： 最常用的一种引用关系，表示Parent Span和Child Span之间存在直接的依赖关系。例RPC服务端Span和RPC客户端Span，或者数据库SQL插入Span和ORM Save动作Span之间的关系。 FollowsFrom：如果Parent Span并不依赖Child Span的执行结果，则可以用FollowsFrom表示。例如网上商店购物付款后会向用户发一个邮件通知，但无论邮件通知是否发送成功，都不影响付款成功的状态，这种情况则适用于用FollowsFrom表示。 跨进程调用信息传播 SpanContext是OpenTracing中一个让人比较迷惑的概念。在OpenTracing的概念模型中提到SpanContext用于跨进程边界传递分布式调用的上下文。但实际上OpenTracing只定义一个SpanContext的抽象接口，该接口封装了分布式调用中一个Span的相关上下文内容，包括该Span所属的Trace id，Span id以及其它需要传递到downstream服务的信息。SpanContext自身并不能实现跨进程的上下文传递，需要由Tracer（Tracer是一个遵循OpenTracing协议的实现，如Jaeger，Skywalking的Tracer）将SpanContext序列化后通过Wire Protocol传递到下一个进程中，然后在下一个进程将SpanContext反序列化，得到相关的上下文信息，以用于生成Child Span。 为了为各种具体实现提供最大的灵活性，OpenTracing只是提出了跨进程传递SpanContext的要求，并未规定将SpanContext进行序列化并在网络中传递的具体实现方式。各个不同的Tracer可以根据自己的情况使用不同的Wire Protocol来传递SpanContext。 在基于HTTP协议的分布式调用中，通常会使用HTTP Header来传递SpanContext的内容。常见的Wire Protocol包含Zipkin使用的b3 HTTP header，Jaeger使用的uber-trace-id HTTP Header,LightStep使用的\"x-ot-span-context\" HTTP Header等。Istio/Envoy支持b3 header和x-ot-span-context header,可以和Zipkin,Jaeger及LightStep对接。其中b3 HTTP header的示例如下： X-B3-TraceId: 80f198ee56343ba864fe8b2a57d3eff7 X-B3-ParentSpanId: 05e3ac9a4f6e3b90 X-B3-SpanId: e457b5a2e4d86bd1 X-B3-Sampled: 1 Istio对分布式调用跟踪的支持 Istio/Envoy为微服务提供了开箱即用的分布式调用跟踪功能。在安装了Istio和Envoy的微服务系统中，Envoy会拦截服务的入向和出向请求，为微服务的每个调用请求自动生成调用跟踪数据。通过在服务网格中接入一个分布式跟踪的后端系统，例如zipkin或者Jaeger，就可以查看一个分布式请求的详细内容，例如该请求经过了哪些服务，调用了哪个REST接口，每个REST接口所花费的时间等。 需要注意的是，Istio/Envoy虽然在此过程中完成了大部分工作，但还是要求对应用代码进行少量修改：应用代码中需要将收到的上游HTTP请求中的b3 header拷贝到其向下游发起的HTTP请求的header中，以将调用跟踪上下文传递到下游服务。这部分代码不能由Envoy代劳，原因是Envoy并不清楚其代理的服务中的业务逻辑，无法将入向请求和出向请求按照业务逻辑进行关联。这部分代码量虽然不大，但需要对每一处发起HTTP请求的代码都进行修改，非常繁琐而且容易遗漏。当然，可以将发起HTTP请求的代码封装为一个代码库来供业务模块使用，来简化该工作。 下面以一个简单的网上商店示例程序来展示Istio如何提供分布式调用跟踪。该示例程序由eshop,inventory，billing，delivery几个微服务组成，结构如下图所示： eshop微服务接收来自客户端的请求，然后调用inventory，billing，delivery这几个后端微服务的REST接口来实现用户购买商品的checkout业务逻辑。本例的代码可以从github下载：https://github.com/aeraki-framework/method-level-tracing-with-istio 如下面的代码所示，我们需要在eshop微服务的应用代码中传递b3 HTTP Header。 @RequestMapping(value = \"/checkout\") public String checkout(@RequestHeader HttpHeaders headers) { String result = \"\"; // Use HTTP GET in this demo. In a real world use case,We should use HTTP POST // instead. // The three services are bundled in one jar for simplicity. To make it work, // define three services in Kubernets. result += restTemplate.exchange(\"http://inventory:8080/createOrder\", HttpMethod.GET, new HttpEntity<>(passTracingHeader(headers)), String.class).getBody(); result += \"\"; result += restTemplate.exchange(\"http://billing:8080/payment\", HttpMethod.GET, new HttpEntity<>(passTracingHeader(headers)), String.class).getBody(); result += \"\"; result += restTemplate.exchange(\"http://delivery:8080/arrangeDelivery\", HttpMethod.GET, new HttpEntity<>(passTracingHeader(headers)), String.class).getBody(); return result; } private HttpHeaders passTracingHeader(HttpHeaders headers) { HttpHeaders tracingHeaders = new HttpHeaders(); extractHeader(headers, tracingHeaders, \"x-request-id\"); extractHeader(headers, tracingHeaders, \"x-b3-traceid\"); extractHeader(headers, tracingHeaders, \"x-b3-spanid\"); extractHeader(headers, tracingHeaders, \"x-b3-parentspanid\"); extractHeader(headers, tracingHeaders, \"x-b3-sampled\"); extractHeader(headers, tracingHeaders, \"x-b3-flags\"); extractHeader(headers, tracingHeaders, \"x-ot-span-context\"); return tracingHeaders; } 下面我们来测试一下eshop实例程序。我们可以自己搭建一个Kubernetes集群并安装Istio以用于测试。这里为了方便，直接使用腾讯云上提供的全托管的服务网格 TCM，并在创建的 Mesh 中加入了一个容器服务TKE 集群来进行测试。 在 TKE 集群中部署该程序，查看Istio分布式调用跟踪的效果。 git clone git@github.com:aeraki-framework/method-level-tracing-with-istio.git cd method-level-tracing-with-istio git checkout without-opentracing kubectl apply -f k8s/eshop.yaml 在浏览器中打开地址：http://${INGRESS_EXTERNAL_IP}/checkout ，以触发调用eshop示例程序的REST接口。 在浏览器中打开 TCM 的界面，查看生成的分布式调用跟踪信息。 TCM 图形界面直观地展示了这次调用的详细信息，可以看到客户端请求从Ingressgateway进入到系统中，然后调用了eshop微服务的checkout接口，checkout调用有三个child span，分别对应到inventory，billing和delivery三个微服务的REST接口。 使用OpenTracing来传递分布式跟踪上下文 OpenTracing提供了基于Spring的代码埋点，因此我们可以使用OpenTracing Spring框架来提供HTTP header的传递，以避免这部分硬编码工作。在Spring中采用OpenTracing来传递分布式跟踪上下文非常简单，只需要下述两个步骤： 在Maven POM文件中声明相关的依赖，一是对OpenTracing SPring Cloud Starter的依赖；另外由于Istio 采用了Zipkin的上报接口，我们也需要引入Zipkin的相关依赖。 在Spring Application中声明一个Tracer bean。如下所示，注意我们需要把 Istio 中的zpkin上报地址设置到OKHttpSernder中。 @Bean public io.opentracing.Tracer zipkinTracer() { String zipkinEndpoint = System.getenv(\"ZIPKIN_ENDPOINT\"); if (zipkinEndpoint == null || zipkinEndpoint == \"\"){ zipkinEndpoint = \"http://zipkin.istio-system:9411/api/v2/spans\"; } OkHttpSender sender = OkHttpSender.create(zipkinEndpoint); Reporter spanReporter = AsyncReporter.create(sender); Tracing braveTracing = Tracing.newBuilder() .localServiceName(\"my-service\") .propagationFactory(B3Propagation.FACTORY) .spanReporter(spanReporter) .build(); Tracing braveTracer = Tracing.newBuilder() .localServiceName(\"spring-boot\") .spanReporter(spanReporter) .propagationFactory(B3Propagation.FACTORY) .traceId128Bit(true) .sampler(Sampler.ALWAYS_SAMPLE) .build(); return BraveTracer.create(braveTracer); } 部署采用OpenTracing进行HTTP header传递的程序版本，其调用跟踪信息如下所示： 从上图中可以看到，相比在应用代码中直接传递HTTP header的方式，采用OpenTracing进行代码埋点后，相同的调用增加了7个名称前缀为spring-boot的Span，这7个Span是由OpenTracing的tracer生成的。虽然我们并没有在代码中显示创建这些Span，但OpenTracing的代码埋点会自动为每一个REST请求生成一个Span，并根据调用关系关联起来。 OpenTracing生成的这些Span为我们提供了更详细的分布式调用跟踪信息，从这些信息中可以分析出一个HTTP调用从客户端应用代码发起请求，到经过客户端的Envoy，再到服务端的Envoy，最后到服务端接受到请求各个步骤的耗时情况。从图中可以看到，Envoy转发的耗时在1毫秒左右，相对于业务代码的处理时长非常短，对这个应用而言，Envoy的处理和转发对于业务请求的处理效率基本没有影响。 在Istio调用跟踪链中加入方法级的调用跟踪信息 Istio/Envoy提供了跨服务边界的调用链信息，在大部分情况下，服务粒度的调用链信息对于系统性能和故障分析已经足够。但对于某些服务，需要采用更细粒度的调用信息来进行分析，例如一个REST请求内部的业务逻辑和数据库访问分别的耗时情况。在这种情况下，我们需要在服务代码中进行埋点，并将服务代码中上报的调用跟踪数据和Envoy生成的调用跟踪数据进行关联，以统一呈现Envoy和服务代码中生成的调用数据。 在方法中增加调用跟踪的代码是类似的，因此我们用AOP + Annotation的方式实现，以简化代码。 首先定义一个Traced注解和对应的AOP实现逻辑： @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD) @Documented public @interface Traced { } @Aspect @Component public class TracingAspect { @Autowired Tracer tracer; @Around(\"@annotation(com.zhaohuabing.demo.instrument.Traced)\") public Object aroundAdvice(ProceedingJoinPoint jp) throws Throwable { String class_name = jp.getTarget().getClass().getName(); String method_name = jp.getSignature().getName(); Span span = tracer.buildSpan(class_name + \".\" + method_name).withTag(\"class\", class_name) .withTag(\"method\", method_name).start(); Object result = jp.proceed(); span.finish(); return result; } } 然后在需要进行调用跟踪的方法上加上Traced注解： @Component public class DBAccess { @Traced public void save2db() { try { Thread.sleep((long) (Math.random() * 100)); } catch (InterruptedException e) { e.printStackTrace(); } } } @Component public class BankTransaction { @Traced public void transfer() { try { Thread.sleep((long) (Math.random() * 100)); } catch (InterruptedException e) { e.printStackTrace(); } } } demo程序的master branch已经加入了方法级代码跟踪，可以直接部署。 git checkout master kubectl apply -f k8s/eshop.yaml 效果如下图所示，可以看到trace中增加了transfer和save2db两个方法级的Span。 可以打开一个方法的Span，查看详细信息，包括Java类名和调用的方法名等，在AOP代码中还可以根据需要添加出现异常时的异常堆栈等信息。 总结 Istio/Envoy为微服务应用提供了分布式调用跟踪功能，提高了服务调用的可见性。我们可以使用OpenTracing来代替应用硬编码，以传递分布式跟踪的相关http header；还可以通过OpenTracing将方法级的调用信息加入到Istio/Envoy缺省提供的调用链跟踪信息中，以提供更细粒度的调用跟踪信息。 下一步 除了同步调用之外，异步消息也是微服务架构中常见的一种通信方式。在下一篇文章中，我将继续利用eshop demo程序来探讨如何通过OpenTracing将Kafka异步消息也纳入到Istio的分布式调用跟踪中。 参考资料 本文中eshop示例程序的源代码 Opentracing docs Opentracing specification Opentracing wire protocols Istio Trace context propagation Zipkin-b3-propagation OpenTracing Project Deep Dive Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/best-practice/async-message-tracing.html":{"url":"content/best-practice/async-message-tracing.html","title":"在 Istio 中实现异步消息调用跟踪","keywords":"","body":"在实际项目中，除了同步调用之外，异步消息也是微服务架构中常见的一种通信方式。在本篇文章中，我将继续利用eshop demo程序来探讨如何通过OpenTracing将Kafka异步消息也纳入到Istio的分布式调用跟踪中。 eshop 示例程序结构 如下图所示，demo程序中增加了发送和接收Kafka消息的代码。eshop微服务在调用inventory，billing，delivery服务后，发送了一个kafka消息通知，consumer接收到通知后调用notification服务的REST接口向用户发送购买成功的邮件通知。 将Kafka消息处理加入调用链跟踪 植入Kafka OpenTracing代码 首先从github下载代码。 git clone git@github.com:aeraki-framework/method-level-tracing-with-istio.git 可以直接使用该代码，但建议跟随下面的步骤查看相关的代码，以了解各个步骤背后的原理。 根目录下分为了rest-service和kafka-consumer两个目录，rest-service下包含了各个REST服务的代码，kafka-consumer下是Kafka消息消费者的代码。 首先需要将spring kafka和OpenTracing kafka的依赖加入到两个目录下的pom文件中。 org.springframework.kafka spring-kafka io.opentracing.contrib opentracing-kafka-client ${version.opentracing.kafka-client} 在rest-service目录中的KafkaConfig.java中配置消息Producer端的OpenTracing Instrument。TracingProducerInterceptor会在发送Kafka消息时生成发送端的Span。 @Bean public ProducerFactory producerFactory() { Map configProps = new HashMap<>(); configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress); configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class); configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class); configProps.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, TracingProducerInterceptor.class.getName()); return new DefaultKafkaProducerFactory<>(configProps); } 在kafka-consumer目录中的KafkaConfig.java中配置消息Consumer端的OpenTracing Instrument。TracingConsumerInterceptor会在接收到Kafka消息是生成接收端的Span。 @Bean public ConsumerFactory consumerFactory() { Map props = new HashMap<>(); props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress); props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId); props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class); props.put(ConsumerConfig.INTERCEPTOR_CLASSES_CONFIG, TracingConsumerInterceptor.class.getName()); return new DefaultKafkaConsumerFactory<>(props); } 只需要这两步即可完成Spring程序的Kafka OpenTracing代码植入。下面安装并运行示例程序查看效果。 安装Kafka集群 示例程序中使用到了Kafka消息，因此我们在 TKE 集群中部署一个简单的Kafka实例： cd method-level-tracing-with-istio kubectl apply -f k8s/kafka.yaml 部署demo应用 修改Kubernetes yaml部署文件 k8s/eshop.yaml，设置Kafka bootstrap server，以用于demo程序连接到Kafka集群中。 apiVersion: apps/v1 kind: Deployment metadata: name: delivery ...... spec: containers: - name: eshop image: aeraki/istio-opentracing-demo:latest ports: - containerPort: 8080 env: .... //在这里加入Kafka server地址 - name: KAFKA_BOOTSTRAP_SERVERS value: \"kafka-service:9092\" --- apiVersion: apps/v1 kind: Deployment metadata: name: kafka-consumer ...... spec: containers: - name: kafka-consumer image: aeraki/istio-opentracing-demo-kafka-consumer:latest env: .... //在这里加入Kafka server地址 - name: KAFKA_BOOTSTRAP_SERVERS value: \"kafka-service:9092\" 然后部署应用程序，相关的镜像可以直接从dockerhub下载，也可以通过源码编译生成。 kubectl apply -f k8s/eshop.yaml 在浏览器中打开地址：http://${INGRESS_EXTERNAL_IP}/checkout ，以触发调用eshop示例程序的REST接口。然后打开 TCM 的界面查看生成的分布式调用跟踪信息。 从图中可以看到，在调用链中增加了两个Span，分布对应于Kafka消息发送和接收的两个操作。由于Kafka消息的处理是异步的，消息发送端不直接依赖接收端的处理。根据OpenTracing对引用关系的定义，From_eshop_topic Span 对 To_eshop_topic Span 的引用关系是 FOLLOWS_FROM 而不是 CHILD_OF 关系。 将调用跟踪上下文从Kafka传递到REST服务 现在eshop代码中已经加入了REST和Kafka的OpenTracing Instrumentation，可以在进行REST调用和发送Kafka消息时生成调用跟踪信息。但如果需要从Kafka的消息消费者的处理方法中调用一个REST接口呢？ 我们会发现在eshop示例程序中，缺省生成的调用链里面并不会把Kafka消费者的Span和其发起的调用notification服务的REST请求的Span关联在同一个Trace中。 要分析导致该问题的原因，我们首先需要了解“Active Span”的概念。在OpenTracing中，一个线程可以有一个Active Span，该Active Span代表了目前该线程正在执行的工作。在调用Tracer.buildSpan()方法创建新的Span时，如果Tracer目前存在一个Active Span，则会将该Active Span缺省作为新创建的Span的Parent Span。 Tracer.buildSpan 方法的说明如下： Tracer.SpanBuilder buildSpan(String operationName) Return a new SpanBuilder for a Span with the given `operationName`. You can override the operationName later via BaseSpan.setOperationName(String). A contrived example: Tracer tracer = ... // Note: if there is a `tracer.activeSpan()`, it will be used as the target of an implicit CHILD_OF // Reference for \"workSpan\" when `startActive()` is invoked. // 如果存在active span，则其创建的新Span会隐式地创建一个 CHILD_OF 引用到该active span try (ActiveSpan workSpan = tracer.buildSpan(\"DoWork\").startActive()) { workSpan.setTag(\"...\", \"...\"); // etc, etc } // 也可以通过asChildOf方法指定新创建的Span的Parent Span // It's also possible to create Spans manually, bypassing the ActiveSpanSource activation. Span http = tracer.buildSpan(\"HandleHTTPRequest\") .asChildOf(rpcSpanContext) // an explicit parent .withTag(\"user_agent\", req.UserAgent) .withTag(\"lucky_number\", 42) .startManual(); 分析Kafka OpenTracing Instrumentation的代码，会发现TracingConsumerInterceptor在调用Kafka消费者的处理方法之前已经把消费者的Span结束了，因此发起REST调用时tracer没有active span，不会将Kafka消费者的Span作为后面REST调用的parent span。 public static void buildAndFinishChildSpan(ConsumerRecord record, Tracer tracer, BiFunction consumerSpanNameProvider) { SpanContext parentContext = TracingKafkaUtils.extractSpanContext(record.headers(), tracer); String consumerOper = FROM_PREFIX + record.topic(); // 此时TracingConsumerInterceptor已经将Kafka消费者的Span放到了Kafka消息的header中，因此从Kafka消息头中取出该Span，显示地将Kafka消费者的Span作为REST调用的Parent Span即可。 为MessageConsumer.java使用的RestTemplate设置一个TracingKafka2RestTemplateInterceptor。 @KafkaListener(topics = \"eshop-topic\") public void receiveMessage(ConsumerRecord record) { restTemplate .setInterceptors(Collections.singletonList(new TracingKafka2RestTemplateInterceptor(record.headers()))); restTemplate.getForEntity(\"http://notification:8080/sendEmail\", String.class); } TracingKafka2RestTemplateInterceptor是基于Spring OpenTracing Instrumentation的TracingRestTemplateInterceptor修改的，将从Kafka header中取出的Span设置为出向请求的Span的Parent Span。 @Override public ClientHttpResponse intercept(HttpRequest httpRequest, byte[] body, ClientHttpRequestExecution xecution) throws IOException { ClientHttpResponse httpResponse; SpanContext parentSpanContext = TracingKafkaUtils.extractSpanContext(headers, tracer); Span span = tracer.buildSpan(httpRequest.getMethod().toString()).asChildOf(parentSpanContext) .withTag(Tags.SPAN_KIND.getKey(), Tags.SPAN_KIND_CLIENT).start(); ...... } 在浏览器中打开地址：http://${INGRESS_EXTERNAL_IP}/checkout ，以触发调用eshop示例程序的REST接口。然后打开 TCM 的界面查看生成的分布式调用跟踪信息。 从上图可以看到，调用链中出现了Kafka消费者调用notification服务的sendEmail REST接口的Span。从图中可以看到，由于调用链经过了Kafka消息，sendEmail Span的时间没有包含在checkout Span中。 总结 Istio服务网格通过分布式调用跟踪来提高微服务应用的可见性，这需要在应用程序中通过HTTP header传递调用跟踪的上下文。对于JAVA应用程序，我们可以使用OpenTracing Instrumentation来代替应用编码传递分布式跟踪的相关http header，以减少对业务代码的影响；我们还可以将方法级的调用跟踪和Kafka消息的调用跟踪加入到Istio生成的调用跟踪链中，以为应用程序的故障定位提供更为丰富详细的调用跟踪信息。 参考资料 本文中eshop示例程序的源代码 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/best-practice/http-header-case.html":{"url":"content/best-practice/http-header-case.html","title":"在 Istio 中指定 HTTP Header 大小写","keywords":"","body":"在 Istio 中指定 HTTP Header 大小写 问题背景 Envoy 缺省会把 HTTP Header 的 key 转换为小写，例如有一个 HTTP Header Test-Upper-Case-Header: some-value，经过 Envoy 代理后会变成 test-upper-case-header: some-value。这个在正常情况下没问题，RFC 2616 规范也说明了处理 HTTP Header 应该是大小写不敏感的。 部分场景下，业务请求对某些 Header 字段有大小写要求，此时被 Envoy 转换成为小些会导致请求出现问题。 解决方案 Envoy 支持几种不同的 Header 规则： 全小写（默认规则） 首字母大写 Envoy 1.8 之后新增支持： 保留请求原本样式 基于以上能力，为了解决 Header 默认改为小写的问题在 Istio 1.8 及之前可配置成为首字母大写形式，Istio 1.10 及以后可以配置保留 Header 原有样式。 配置方法 Istio 1.8 之前可添加如下 EnvoyFilter 配置： apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: name: http-header-proper-case-words namespace: istio-system spec: configPatches: - applyTo: CLUSTER match: context: SIDECAR_OUTBOUND cluster: # 集群名称可通过ConfigDump查询 name: \"outbound|3000||test2.default.svc.cluster.local\" patch: operation: MERGE value: http_protocol_options: header_key_format: proper_case_words: {} 在需要依赖大写 Header 的服务对应的集群中添加规则，将 Header 全部转为首字母大写的形式。 Istio 1.10 及之后可以添加如下 EnvoyFilter 配置： apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: name: http-header-proper-case-words namespace: istio-system spec: configPatches: - applyTo: NETWORK_FILTER match: listener: filterChain: filter: name: \"envoy.http_connection_manager\" patch: operation: MERGE value: name: \"envoy.http_connection_manager\" typed_config: \"@type\": \"type.googleapis.com/envoy.extensions.filters.network.http_connection_manager.v3.HttpConnectionManager\" http_protocol_options: header_key_format: stateful_formatter: name: preserve_case typed_config: \"@type\": type.googleapis.com/envoy.extensions.http.header_formatters.preserve_case.v3.PreserveCaseFormatterConfig 通过此配置可以让 Enovy 保持 Header 原有大小写形式。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "},"content/tcm/":{"url":"content/tcm/","title":"腾讯云服务网格 TCM","keywords":"","body":"TCM（Tencent Cloud Mesh）是腾讯云上提供的基于Istio进行增强，和Istio API完全兼容的Service Mesh托管服务，可以帮助用户以较小的迁移成本和维护代价快速利用到Service Mesh提供的流量管理和服务治理能力。 Copyright © Aeraki Framework 2021 all right reserved，powered by Gitbook Updated at 2021-11-11 07:37:57 "}}